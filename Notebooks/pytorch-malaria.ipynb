{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model for Malaria Detection using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deep learning models run a lot faster on GPUs than on CPUs . Thus we will use GPU for computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use Pytorch transformation to augment the dataset :\n",
    "- Resized the images to 120 * 120 as an input to custom CNN class\n",
    "- Applied transformations like RandomHorizontalFlip( ), RandomRotation( ) and RandomVerticalFlip( )\n",
    "- Converted the images to Pytorch tensors\n",
    "- Also normalizing them with mean [0.5, 0.5., 0.5] and standard deviation [0.5, 0.5, 0.5]. All tensors are in range of [-1, 1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([transforms.Resize((120, 120)),\n",
    "                                     transforms.ColorJitter(0.05),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.RandomVerticalFlip(), \n",
    "                                     transforms.RandomRotation(20),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now lets Load images using dataloader ImageFolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"../input/cell-images-for-detecting-malaria/cell_images/cell_images\"\n",
    "dataset = datasets.ImageFolder(images_dir, transform=data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 27558 | Train size: 22047 | Test size: 5511\n"
     ]
    }
   ],
   "source": [
    "test_size = int(0.2*len(dataset))\n",
    "train_size = len(dataset) - test_size\n",
    "\n",
    "train, test = random_split(dataset, lengths = [train_size, test_size])\n",
    "\n",
    "print(f'Dataset size: {len(dataset)} | Train size: {len(train)} | Test size: {len(test)}')\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=32)\n",
    "test_loader = DataLoader(test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have images in 2 classes: Infected and Uninfected\n",
    "classes=['infected','uninfected']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN class\n",
    "\n",
    "- Creating a CNN class as MosquitoNet.\n",
    "- It has following layers:\n",
    "  - 3 Convolutional layers with MaxPooling (Stride 2)\n",
    "  -  All 3 convulations are \"Same Convolution with some zero-padding\"\n",
    "  -  3 FullyConnected Layers\n",
    "- BatchNormalization is used after convulations\n",
    "- ReLU is used as a activation function\n",
    "- Dropout is used with p = 0.5\n",
    "\n",
    "- Images are changed from input to output layers in following way:\n",
    "\n",
    "  - In Layer 1 : Input: 120 * 120 * 3, Output: 60 * 60 * 16\n",
    "  - In Layer 2 : Input: 60 * 60 * 16, Output: 30 * 30 * 32\n",
    "  - In Layer 3 : Input: 30 * 30 * 32, Output: 15 * 15 * 64\n",
    "  - In FC1 : Input: 14440, Output: 512\n",
    "  - In FC2 : Input: 512, Output: 128\n",
    "  - In FC3 : Input: 128, Output: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MosquitoNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MosquitoNet, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "            \n",
    "        self.fc1 = nn.Linear(64*15*15, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 2)\n",
    "        self.drop = nn.Dropout2d(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)    # flatten out a input for Dense Layer\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MosquitoNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=14400, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (drop): Dropout2d(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Making a model and defining error and optimizing algorithm.\n",
    "model = MosquitoNet()\n",
    "model.to(device)\n",
    "error = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.1394\n",
      "Epoch: 2, Loss: 0.5372\n",
      "Epoch: 3, Loss: 0.4837\n",
      "Epoch: 4, Loss: 0.4665\n",
      "Epoch: 5, Loss: 0.4383\n",
      "Epoch: 6, Loss: 0.4136\n",
      "Epoch: 7, Loss: 0.4157\n",
      "Epoch: 8, Loss: 0.3925\n",
      "Epoch: 9, Loss: 0.3898\n",
      "Epoch: 10, Loss: 0.3864\n",
      "Epoch: 11, Loss: 0.3749\n",
      "Epoch: 12, Loss: 0.3715\n",
      "Epoch: 13, Loss: 0.3593\n",
      "Epoch: 14, Loss: 0.3512\n",
      "Epoch: 15, Loss: 0.3572\n",
      "Epoch: 16, Loss: 0.3364\n",
      "Epoch: 17, Loss: 0.3383\n",
      "Epoch: 18, Loss: 0.3308\n",
      "Epoch: 19, Loss: 0.3255\n",
      "Epoch: 20, Loss: 0.3212\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 100 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.\n",
    "    model.train()    # explictily stating the training\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        train = images.view(-1, 3, 120, 120)\n",
    "        outputs = model(train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = error(outputs, labels)\n",
    "        loss.backward()    #back-propagation\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * batch_size\n",
    "     \n",
    "    print(\"Epoch: {}, Loss: {:.4f}\".format(epoch + 1, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
